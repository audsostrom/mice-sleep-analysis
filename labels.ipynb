{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "X_aRJoxGVwGR"
      },
      "outputs": [],
      "source": [
        "import tkinter as tk #tk for file dialog (requires Jinja2!!!)\n",
        "from tkinter import filedialog #tkinter for file dialog\n",
        "\n",
        "import re #regex for parsing\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os\n",
        "from os.path import exists\n",
        "import torch\n",
        "\n",
        "def isTextFile(filepath):\n",
        "\tfLen = len(filepath)\n",
        "\t#Check that our filepath is a .txt\n",
        "\treturn bool((fLen > 4) and (filepath[fLen-4:] == \".txt\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "roohmDoTVwJw"
      },
      "outputs": [],
      "source": [
        "#any data that doesn't make a full epoch gets cut off im pretty sure (because the epoch tensor is size INT(maxSize/epoch_size))\n",
        "def getTensorFromText(filepath, maxSize=None, epoch_size = 100):## just change the \n",
        "\t#Check that our filepath is a .txt\")\n",
        "    if (isTextFile(filepath)):\n",
        "        dataFp = open(filepath, \"r\")\n",
        "        readingData = False\n",
        "        col1, col2, col3,  col4 = [], [], [], []\n",
        "\n",
        "        line_count = 0\n",
        "\n",
        "        epoch_tensor = torch.zeros(int(maxSize/epoch_size), 3, epoch_size)#tensor to hold each epoch of data\n",
        "        epoch_start = 0\n",
        "        epoch_end = epoch_size\n",
        "        epoch_index = 0\n",
        "\n",
        "        for line in dataFp.readlines():\n",
        "            if ((maxSize != None) and (maxSize <= line_count)):\n",
        "                break\n",
        "\n",
        "            if epoch_start >= epoch_end:\n",
        "                epoch = torch.Tensor([col1, col2, col3])#im just getting one of the time series columns for now for simplicities sake\n",
        "                epoch_tensor[epoch_index] = epoch\n",
        "                col1, col2, col3, col4 = [], [], [], []                \n",
        "                epoch_end += epoch_size\n",
        "                epoch_index += 1\n",
        "\n",
        "            if readingData:                                        \n",
        "\t\t\t\t#split the line by tabs and add the data to our column lists\n",
        "                data_list = line.split(\"\\t\")\n",
        "                stripped_time = re.sub(\"\\s\", \"\",data_list[1])\n",
        "                time = stripped_time.split(\":\")\n",
        "\n",
        "                col1.append(int(time[0]))#idk how much it matters for storage but it might be easier to multiply this by 60\n",
        "                col2.append(np.float32(time[1]))#i think we do need this to be precise because the timesteps should be consitent so i changed it to 32\n",
        "                col3.append(np.float16(re.sub(\"\\s\", \"\",data_list[2])))\n",
        "                col4.append(np.float16(re.sub(\"\\s\", \"\",data_list[3])))\n",
        "\n",
        "                line_count += 1\n",
        "                epoch_start += 1\n",
        "                \n",
        "\t\t\t\t#Ignore initial lines\n",
        "            else:\t\t\n",
        "                stripped = re.sub(\"\\s\", \"\", line)\n",
        "\t\t\t\t\t#This line is the last line before data comes\n",
        "                if stripped == \"(m:s.ms)(mV)(mV)\":\n",
        "                    readingData = True\n",
        "\n",
        "        dataFp.close()\n",
        "\n",
        "        return epoch_tensor\n",
        "    else:\n",
        "        print(\"Cannot handle file\", filepath)\n",
        "        return None\t"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 294
        },
        "id": "aMqFg0NkVwM7",
        "outputId": "77901ce3-0d22-4981-cdb6-196d07982e32"
      },
      "outputs": [],
      "source": [
        "eeg_tensor = getTensorFromText(\"../CHDCtrl1_CHD801FR_normal/CHD801FR_20221123_normal.txt\", maxSize =1000000, epoch_size = 200)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "YTv3hIFZVwQD"
      },
      "outputs": [],
      "source": [
        "eeg_df = pd.DataFrame(eeg_tensor[:, :, 0]).astype(\"float\")\n",
        "end_df = pd.DataFrame(eeg_tensor[:, :, 199]).astype(\"float\")\n",
        "\n",
        "eeg_df = eeg_df.rename(columns={0: \"min\", 1: \"sec\", 2:\"sig\"})\n",
        "eeg_df[\"min\"] = (eeg_df[\"min\"]*60) + eeg_df.sec\n",
        "\n",
        "end_df = end_df.rename(columns={0: \"min\", 1: \"sec\", 2:\"sig\"})\n",
        "end_df[\"sec\"] = (end_df[\"min\"]*60) + end_df.sec\n",
        "\n",
        "eeg_df[\"sec\"] = end_df[\"sec\"]\n",
        "eeg_df = eeg_df.rename(columns={\"min\": \"start\", \"sec\": \"end\"})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "7OzH1P5cVwSk"
      },
      "outputs": [],
      "source": [
        "def getStatesOverTime(filepath):## just change the \n",
        "\t#Check that our filepath is a .txt\")\n",
        "    time, state = [], []\n",
        "    \n",
        "    data_an = open(filepath)#open and read file\n",
        "    r = data_an.read()\n",
        "    data_an.close()\n",
        "\n",
        "    rows = list(r.split(\"\\n\"))#list of each row (strings)\n",
        "    for row in rows:\n",
        "        row_list = list(row.split(\",\"))\n",
        "        if row_list == [\"\"]:\n",
        "            break\n",
        "\n",
        "        time.append(np.float32(row_list[2]))\n",
        "        state.append(int(row_list[5]))\n",
        "\n",
        "    return [time, state]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "WJyW7r9MWtd_"
      },
      "outputs": [],
      "source": [
        "statesOverTime = getStatesOverTime(\"../CHDCtrl1_CHD801FR_normal/CHD801FR_20221123_normal_annotated.txt\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "3d9hhFmMW0dn"
      },
      "outputs": [],
      "source": [
        "def add_state_column(s = 0, e = 10000):\n",
        "\n",
        "    states_col = []\n",
        "    epoch_i = 1\n",
        "    time_state_i = 1\n",
        "\n",
        "    for index, row in eeg_df[s:e].iterrows():\n",
        "        epoch_start = row[\"start\"]\n",
        "        epoch_end = row[\"end\"]\n",
        "\n",
        "        if epoch_end >= statesOverTime[0][time_state_i]:\n",
        "            \n",
        "            if epoch_start < statesOverTime[0][time_state_i]:\n",
        "                states_col.append(4)\n",
        "\n",
        "            else:\n",
        "                states_col.append(statesOverTime[1][time_state_i])\n",
        "            time_state_i += 1\n",
        "\n",
        "        else:\n",
        "            states_col.append(statesOverTime[1][time_state_i])\n",
        "\n",
        "        epoch_i += 1\n",
        "  \n",
        "    return(states_col)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "fRT9se_QW0oD"
      },
      "outputs": [],
      "source": [
        "labels = add_state_column()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "6xSe2NwXW0sT"
      },
      "outputs": [],
      "source": [
        "ds = torch.utils.data.TensorDataset(eeg_tensor, torch.tensor(labels))\n",
        "train_loader = torch.utils.data.DataLoader(ds, batch_size=64, shuffle=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "bm8XVWxEOJOj"
      },
      "outputs": [],
      "source": [
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "9wKR1Xg6MSby"
      },
      "outputs": [],
      "source": [
        "import torch.nn.functional as F\n",
        "from torch import nn, optim\n",
        "\n",
        "class Model_3(nn.Module):\n",
        "    def __init__(self, input_size, n_feature, output_size):\n",
        "        super(Model_3, self).__init__()\n",
        "        self.n_feature = n_feature\n",
        "        self.conv1 = nn.Conv1d(in_channels=3, out_channels=n_feature, kernel_size=(3))\n",
        "        self.fc1 = nn.Linear(135168, 10)#64*28*28\n",
        "        self.fc2 = nn.Linear(10, 10)\n",
        "\n",
        "    def forward(self, x, verbose=False):\n",
        "        #print(x.size())\n",
        "        x = self.conv1(x)\n",
        "        x = F.relu(x)\n",
        "        #print(x.size())\n",
        "        x = F.max_pool2d(x, kernel_size=(1, 3))\n",
        "        #print(x.size())\n",
        "        x = F.relu(x)\n",
        "        #x = F.max_pool2d(x, kernel_size=(1, 3))\n",
        "        #print(x.size())\n",
        "        x = x.size()[0]\n",
        "        x = x.view(x, -1)\n",
        "        x = self.fc1(x)\n",
        "        x = F.relu(x)\n",
        "        x = self.fc2(x)\n",
        "        x = F.log_softmax(x, dim=1)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "NsjuBjvJMYr8"
      },
      "outputs": [],
      "source": [
        "def train_model(epochs, model):\n",
        "    model.train() #set model to training mode\n",
        "    loss_fun = nn.CrossEntropyLoss() #define a loss function object\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "\n",
        "      for batch_idx, (data, target) in enumerate(train_loader):\n",
        "          # send to device\n",
        "          data, target = data.to(device), target.to(device)\n",
        "\n",
        "          \n",
        "          optimizer.zero_grad()\n",
        "          output = model(data)\n",
        "          loss = loss_fun(output,target)\n",
        "          loss.backward()\n",
        "          optimizer.step()\n",
        "          if batch_idx % 100 == 0:\n",
        "              print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
        "                  epoch, batch_idx * len(data), len(trainloader.dataset),\n",
        "                  100. * batch_idx / len(trainloader), loss.item()))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "P744BGwtMa-a"
      },
      "outputs": [
        {
          "ename": "IndexError",
          "evalue": "Dimension out of range (expected to be in range of [-1, 0], but got 1)",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[26], line 5\u001b[0m\n\u001b[1;32m      2\u001b[0m model_step_3\u001b[39m.\u001b[39mto(device)\n\u001b[1;32m      4\u001b[0m optimizer \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39moptim\u001b[39m.\u001b[39mSGD(model_step_3\u001b[39m.\u001b[39mparameters(), lr\u001b[39m=\u001b[39m\u001b[39m.01\u001b[39m)\n\u001b[0;32m----> 5\u001b[0m train_model(\u001b[39m10\u001b[39;49m, model_step_3)\n",
            "Cell \u001b[0;32mIn[25], line 13\u001b[0m, in \u001b[0;36mtrain_model\u001b[0;34m(epochs, model)\u001b[0m\n\u001b[1;32m      9\u001b[0m data, target \u001b[39m=\u001b[39m data\u001b[39m.\u001b[39mto(device), target\u001b[39m.\u001b[39mto(device)\n\u001b[1;32m     12\u001b[0m optimizer\u001b[39m.\u001b[39mzero_grad()\n\u001b[0;32m---> 13\u001b[0m output \u001b[39m=\u001b[39m model(data)\n\u001b[1;32m     14\u001b[0m loss \u001b[39m=\u001b[39m loss_fun(output,target)\n\u001b[1;32m     15\u001b[0m loss\u001b[39m.\u001b[39mbackward()\n",
            "File \u001b[0;32m~/Library/Python/3.8/lib/python/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
            "Cell \u001b[0;32mIn[24], line 26\u001b[0m, in \u001b[0;36mModel_3.forward\u001b[0;34m(self, x, verbose)\u001b[0m\n\u001b[1;32m     24\u001b[0m x \u001b[39m=\u001b[39m F\u001b[39m.\u001b[39mrelu(x)\n\u001b[1;32m     25\u001b[0m x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfc2(x)\n\u001b[0;32m---> 26\u001b[0m x \u001b[39m=\u001b[39m F\u001b[39m.\u001b[39;49mlog_softmax(x, dim\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m)\n\u001b[1;32m     27\u001b[0m \u001b[39mreturn\u001b[39;00m x\n",
            "File \u001b[0;32m~/Library/Python/3.8/lib/python/site-packages/torch/nn/functional.py:1932\u001b[0m, in \u001b[0;36mlog_softmax\u001b[0;34m(input, dim, _stacklevel, dtype)\u001b[0m\n\u001b[1;32m   1930\u001b[0m     dim \u001b[39m=\u001b[39m _get_softmax_dim(\u001b[39m\"\u001b[39m\u001b[39mlog_softmax\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39minput\u001b[39m\u001b[39m.\u001b[39mdim(), _stacklevel)\n\u001b[1;32m   1931\u001b[0m \u001b[39mif\u001b[39;00m dtype \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m-> 1932\u001b[0m     ret \u001b[39m=\u001b[39m \u001b[39minput\u001b[39;49m\u001b[39m.\u001b[39;49mlog_softmax(dim)\n\u001b[1;32m   1933\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   1934\u001b[0m     ret \u001b[39m=\u001b[39m \u001b[39minput\u001b[39m\u001b[39m.\u001b[39mlog_softmax(dim, dtype\u001b[39m=\u001b[39mdtype)\n",
            "\u001b[0;31mIndexError\u001b[0m: Dimension out of range (expected to be in range of [-1, 0], but got 1)"
          ]
        }
      ],
      "source": [
        "model_step_3 = Model_3(3*200, 32, 4)\n",
        "model_step_3.to(device)\n",
        "  \n",
        "optimizer = torch.optim.SGD(model_step_3.parameters(), lr=.01)\n",
        "train_model(10, model_step_3)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
