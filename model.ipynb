{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Draft Model for Mice Steep Stage Analysis**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import re\n",
    "import copy\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "\n",
    "import torch\n",
    "from torch import optim, nn\n",
    "from torchvision import transforms, datasets, models\n",
    "\n",
    "from collections import OrderedDict\n",
    "\n",
    "import torch.utils.data as utils\n",
    "\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "\n",
    "import tkinter as tk #tk for file dialog (requires Jinja2!!!)\n",
    "from tkinter import filedialog #tkinter for file dialog\n",
    "\n",
    "import re #regex for parsing\n",
    "from os.path import exists\n",
    "from inputMassager import *"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we'd import the data and create a dataframe out of it. (SHOUTOUT REGAN!!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputHandler = inputMassager()\n",
    "\n",
    "filepath = inputHandler.askForInput(\"Blah!\")\n",
    "\n",
    "#Period Size Variable : effects CNN architecture\n",
    "periodSize = 200\n",
    "\n",
    "#makePeriodFromTxt(self, filepath, periodSize, maxPeriods=None):\n",
    "temp_df = inputHandler.makePeriodFromTxt(filepath, periodSize, 2000)\n",
    "\n",
    "# target = regan and audreys code ---> This is what will go into the data loader\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time we're on: 1703.0699462890625\n",
      "my time is 1, current epoch is (1.004,2.004)\n",
      "time we're on: 1707.9849853515625\n",
      "my time is 2, current epoch is (1703.441,1704.441)\n",
      "time we're on: 1721.60498046875\n",
      "my time is 3, current epoch is (1708.466,1709.466)\n",
      "time we're on: 1728.739990234375\n",
      "my time is 4, current epoch is (1722.536,1723.536)\n",
      "time we're on: 1732.344970703125\n",
      "my time is 5, current epoch is (1729.571,1730.571)\n",
      "time we're on: 1743.1099853515625\n",
      "my time is 6, current epoch is (1732.586,1733.586)\n",
      "time we're on: 2087.1650390625\n",
      "my time is 7, current epoch is (1743.641,1744.641)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"\\nfigure out how to integrate this\\n\\n# set up training and validation data\\ntrain_data, train_labels, val_data, val_labels = # USE DATAFRAME TO MAKE THIS\\n\\ntrain = \\ntrain_loader = utils.DataLoader(train, batch_size=64, shuffle=True)\\n\\ntest = \\ntest_loader = utils.DataLoader(test, batch_size=64, shuffle=True)\\n\\ndata_loaders = {'train': train_loader, 'valid': test_loader}\\ndataset_sizes = {'train': len(train), 'valid': len(test)}\\n\""
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filepath2 = inputHandler.askForInput(\"Blah!\")\n",
    "timestamps = find_time_labels(temp_df, filepath2)\n",
    "labels = label_dataframe(temp_df, timestamps)\n",
    "\n",
    "labels\n",
    "\"\"\"\n",
    "figure out how to integrate this\n",
    "\n",
    "# set up training and validation data\n",
    "train_data, train_labels, val_data, val_labels = # USE DATAFRAME TO MAKE THIS\n",
    "\n",
    "train = \n",
    "train_loader = utils.DataLoader(train, batch_size=64, shuffle=True)\n",
    "\n",
    "test = \n",
    "test_loader = utils.DataLoader(test, batch_size=64, shuffle=True)\n",
    "\n",
    "data_loaders = {'train': train_loader, 'valid': test_loader}\n",
    "dataset_sizes = {'train': len(train), 'valid': len(test)}\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[list([-0.04, 0.23, 0.2, 0.29, 0.23, 0.22, 0.25, 0.21, 0.24, 0.21, 0.15, 0.22, 0.16, 0.14, 0.19, 0.11, 0.14, 0.17, 0.19, 0.16, 0.19, 0.21, 0.22, 0.28, 0.23, 0.23, 0.29, 0.22, 0.14, 0.12, 0.06, 0.15, 0.2, 0.16, 0.16, 0.14, 0.05, 0.08, 0.08, 0.1, 0.09, 0.06, 0.1, 0.11, 0.08, 0.0, 0.04, 0.04, 0.09, 0.12, 0.17, 0.18, 0.17, 0.19, 0.2, 0.2, 0.22, 0.17, 0.15, 0.02, 0.01, 0.04, 0.04, 0.06, 0.04, 0.02, -0.0, 0.01, 0.03, 0.03, -0.0, 0.08, 0.05, 0.04, 0.03, -0.01, 0.04, 0.1, 0.12, 0.09, 0.13, 0.14, 0.09, 0.11, 0.01, -0.07, -0.05, -0.05, -0.01, -0.02, -0.1, -0.07, -0.09, -0.08, -0.09, -0.11, -0.11, -0.07, -0.09, -0.06, -0.04, -0.05, -0.1, -0.07, -0.13, -0.1, -0.11, -0.09, -0.03, -0.05, -0.08, -0.05, -0.14, -0.06, -0.12, -0.14, -0.17, -0.14, -0.15, -0.07, -0.09, -0.04, 0.02, -0.02, 0.04, 0.02, -0.01, -0.03, 0.01, 0.01, 0.01, -0.02, -0.08, -0.09, -0.09, -0.11, -0.09, -0.09, -0.11, -0.04, -0.09, -0.05, -0.07, -0.05, -0.08, -0.02, -0.01, -0.05, -0.13, 0.04, -0.04, 0.0, -0.08, -0.07, -0.07, -0.1, -0.01, -0.03, -0.07, -0.03, -0.12, -0.13, -0.18, -0.2, -0.14, -0.12, -0.06, -0.08, 0.02, -0.07, -0.13, -0.07, -0.07, -0.02, 0.07, 0.02, 0.0, -0.03, 0.01, -0.05, -0.03, 0.07, -0.09, -0.05, -0.1, -0.09, -0.1, -0.06, -0.03, -0.09, -0.08, -0.03, -0.03, -0.02, 0.05, 0.02, 0.02, 0.04, 0.02, 0.07])\n",
      " list([0.0, 0.13, 0.03, -0.01, -0.02, -0.02, -0.02, -0.07, -0.04, -0.01, -0.05, -0.06, -0.04, -0.09, -0.11, -0.1, -0.11, -0.01, -0.0, 0.02, 0.02, 0.09, 0.15, 0.09, 0.06, 0.01, 0.01, 0.01, -0.09, -0.04, 0.04, 0.1, 0.06, -0.02, 0.04, -0.02, -0.04, -0.06, -0.14, -0.1, -0.15, -0.1, -0.06, -0.06, -0.13, -0.18, -0.08, -0.09, -0.06, 0.02, -0.02, -0.12, -0.14, -0.07, -0.06, -0.11, -0.2, -0.11, -0.21, -0.22, -0.21, -0.19, -0.16, -0.1, -0.04, -0.06, 0.01, -0.04, 0.0, -0.07, -0.05, -0.04, -0.07, -0.05, -0.16, -0.12, -0.12, -0.06, -0.03, -0.05, -0.16, -0.1, -0.13, -0.12, -0.12, -0.18, -0.12, -0.09, -0.05, -0.1, -0.07, -0.02, 0.01, -0.05, -0.09, -0.09, -0.06, -0.06, -0.06, -0.09, -0.05, -0.12, -0.09, -0.09, -0.14, -0.05, -0.06, -0.05, -0.04, -0.05, 0.09, 0.07, 0.04, 0.05, 0.05, 0.05, -0.06, -0.07, -0.0, -0.07, -0.08, -0.1, -0.07, -0.06, -0.15, -0.14, -0.12, -0.15, -0.18, -0.16, -0.18, -0.17, -0.19, -0.17, -0.14, -0.13, -0.14, -0.19, -0.27, -0.22, -0.19, -0.07, -0.1, -0.09, -0.15, -0.11, -0.07, -0.1, -0.12, -0.07, -0.03, -0.11, -0.12, -0.11, -0.07, 0.01, -0.08, -0.08, -0.03, -0.15, -0.1, -0.14, -0.16, -0.15, -0.16, -0.13, -0.02, -0.02, -0.04, -0.03, -0.06, -0.03, -0.08, -0.05, -0.08, -0.19, -0.11, -0.01, -0.04, -0.08, -0.02, 0.01, -0.08, -0.12, -0.09, -0.06, 0.0, 0.0, 0.06, 0.12, 0.06, 0.09, 0.04, -0.02, -0.05, 0.01, 0.02, -0.07, -0.11, 0.04])\n",
      " list([-0.02, -0.08, -0.18, -0.13, -0.05, -0.08, -0.09, -0.04, -0.08, -0.05, -0.0, -0.02, -0.02, 0.02, -0.04, -0.07, -0.07, -0.06, 0.0, 0.02, -0.03, -0.07, -0.1, -0.04, -0.05, -0.04, 0.02, 0.05, 0.05, 0.02, 0.02, 0.07, 0.05, 0.05, 0.0, 0.01, 0.1, 0.08, 0.05, 0.01, 0.02, 0.04, 0.15, 0.05, 0.0, -0.03, -0.06, -0.06, -0.1, -0.11, -0.16, -0.12, -0.2, -0.15, -0.12, -0.09, -0.07, -0.01, -0.01, -0.06, -0.08, -0.12, -0.06, -0.1, -0.1, -0.12, -0.09, -0.11, -0.1, -0.14, -0.07, -0.02, -0.04, -0.07, -0.1, -0.05, -0.08, -0.04, -0.03, 0.04, 0.08, 0.04, 0.01, 0.1, 0.09, 0.12, 0.07, 0.07, 0.09, 0.12, 0.1, 0.09, 0.09, 0.19, 0.12, 0.08, -0.03, 0.02, 0.1, 0.03, -0.01, -0.02, 0.03, 0.04, 0.03, 0.02, 0.1, 0.06, 0.04, 0.01, 0.08, 0.04, 0.05, 0.04, 0.0, 0.06, -0.01, -0.05, -0.02, 0.01, 0.03, -0.02, 0.02, 0.07, 0.13, 0.1, 0.05, 0.02, 0.07, 0.09, 0.12, 0.11, 0.09, 0.04, 0.05, -0.01, 0.01, 0.08, 0.06, 0.01, 0.05, 0.02, 0.01, 0.03, 0.05, 0.07, 0.1, 0.01, 0.06, 0.09, 0.11, 0.13, 0.11, 0.13, 0.19, 0.12, 0.13, 0.09, 0.11, 0.1, 0.11, 0.05, 0.05, 0.02, 0.07, 0.11, 0.05, 0.07, 0.07, -0.0, -0.03, -0.07, -0.02, 0.08, 0.11, 0.12, 0.1, 0.06, 0.04, 0.04, 0.05, 0.06, 0.14, 0.1, 0.02, 0.02, 0.0, -0.02, -0.05, -0.07, 0.05, -0.02, -0.02, -0.06, -0.03, -0.02, -0.02, -0.01, 0.02, 0.04])\n",
      " ...\n",
      " list([-0.02, -0.05, 0.01, 0.0, -0.01, -0.01, -0.02, -0.05, -0.03, 0.02, -0.03, -0.09, -0.12, -0.03, -0.02, -0.01, -0.05, -0.06, -0.07, -0.07, -0.04, -0.03, 0.01, 0.05, 0.01, 0.02, 0.06, 0.1, 0.12, 0.06, 0.09, 0.06, 0.06, 0.01, -0.02, 0.05, 0.03, -0.01, -0.04, -0.02, -0.05, -0.01, -0.02, -0.04, -0.02, 0.01, 0.02, 0.02, -0.06, -0.0, 0.02, 0.06, 0.1, 0.06, 0.04, 0.04, 0.02, 0.03, 0.03, 0.02, 0.1, 0.11, 0.08, 0.05, 0.1, 0.06, 0.06, 0.07, 0.01, 0.0, 0.0, -0.01, 0.02, -0.03, 0.02, 0.01, 0.08, 0.02, 0.04, 0.04, 0.05, 0.08, 0.1, 0.12, 0.1, 0.06, 0.07, 0.02, 0.09, 0.14, 0.13, 0.07, 0.05, -0.01, 0.03, 0.07, 0.01, 0.03, 0.02, -0.02, -0.07, -0.09, -0.05, 0.0, -0.03, 0.04, 0.01, -0.02, -0.04, -0.05, -0.04, 0.02, -0.05, -0.04, -0.01, -0.03, 0.03, 0.03, 0.04, 0.08, 0.03, 0.03, 0.06, 0.05, 0.1, 0.05, 0.07, 0.05, 0.05, 0.03, -0.0, 0.02, 0.01, 0.02, 0.04, 0.04, 0.02, 0.02, -0.04, -0.02, -0.01, 0.06, 0.07, 0.05, 0.04, 0.05, 0.03, 0.07, 0.06, 0.06, 0.06, 0.09, 0.08, 0.01, 0.08, 0.11, 0.11, 0.07, 0.04, 0.02, 0.02, -0.07, -0.01, -0.07, -0.11, -0.12, -0.08, -0.09, -0.11, -0.1, -0.06, -0.03, -0.1, -0.06, -0.06, -0.03, 0.02, -0.01, -0.0, 0.01, 0.02, 0.02, -0.01, 0.01, -0.02, 0.01, -0.02, 0.05, -0.07, -0.01, -0.05, -0.04, -0.05, -0.12, -0.12, -0.07, -0.01, -0.06, -0.07, -0.11])\n",
      " list([-0.03, -0.04, -0.11, -0.08, -0.04, -0.02, -0.02, 0.03, -0.06, -0.0, 0.02, 0.06, 0.04, -0.02, -0.05, -0.06, -0.01, -0.03, -0.02, -0.02, 0.03, -0.02, 0.01, -0.03, -0.04, -0.05, -0.03, -0.03, -0.04, -0.08, -0.09, -0.02, 0.01, -0.0, -0.04, 0.01, 0.01, -0.06, -0.08, -0.05, -0.06, -0.1, -0.08, -0.11, -0.07, 0.01, -0.02, 0.02, -0.01, -0.02, 0.05, 0.01, 0.01, -0.03, -0.03, -0.01, -0.07, -0.03, -0.02, -0.06, -0.09, -0.05, -0.05, -0.0, -0.1, -0.05, 0.06, 0.11, 0.06, 0.05, 0.06, 0.03, 0.02, -0.05, -0.06, 0.08, 0.04, 0.05, 0.01, 0.02, 0.08, 0.07, -0.02, 0.04, 0.01, -0.0, -0.01, -0.04, -0.07, -0.09, -0.14, -0.15, -0.18, -0.16, -0.11, -0.08, -0.08, -0.09, -0.11, -0.1, -0.11, -0.06, -0.1, -0.1, -0.08, -0.06, -0.1, -0.1, -0.08, -0.06, -0.09, -0.09, -0.09, -0.08, -0.09, -0.11, -0.08, -0.09, -0.08, -0.08, -0.06, -0.02, -0.01, -0.03, -0.01, -0.03, -0.07, -0.1, -0.07, -0.05, -0.01, -0.03, -0.04, 0.0, -0.01, -0.09, -0.06, -0.03, -0.02, -0.04, -0.11, -0.03, -0.04, -0.06, -0.06, -0.07, -0.05, -0.04, -0.09, -0.05, -0.03, -0.08, -0.05, -0.06, -0.05, -0.05, -0.09, -0.06, -0.0, -0.03, -0.04, 0.02, 0.06, 0.05, 0.08, 0.06, 0.04, 0.04, 0.1, 0.09, 0.1, 0.06, 0.04, -0.0, -0.02, 0.02, 0.02, 0.06, -0.0, -0.0, -0.01, -0.04, -0.04, -0.01, -0.0, -0.08, -0.09, -0.1, -0.06, -0.01, 0.0, -0.06, 0.01, 0.08, 0.07, 0.08, 0.1, 0.07, 0.13, 0.1])\n",
      " list([0.1, 0.1, 0.05, 0.06, 0.04, 0.04, 0.09, 0.02, 0.04, 0.02, -0.01, -0.0, -0.05, -0.02, -0.0, -0.0, -0.05, -0.02, -0.02, -0.07, -0.07, -0.08, -0.02, 0.01, -0.01, -0.0, 0.02, -0.01, 0.03, 0.04, 0.04, 0.03, 0.03, 0.06, 0.09, 0.04, -0.03, 0.02, -0.02, 0.01, 0.01, -0.03, -0.04, -0.12, -0.09, -0.05, -0.02, -0.04, -0.08, -0.07, -0.01, 0.04, 0.05, 0.01, 0.04, -0.01, -0.01, -0.02, 0.02, -0.01, 0.03, 0.03, 0.07, 0.07, 0.03, 0.02, -0.03, -0.05, 0.02, 0.03, 0.02, -0.02, 0.06, 0.03, 0.02, -0.01, -0.02, 0.06, 0.05, 0.0, 0.01, -0.02, -0.13, -0.05, -0.11, -0.11, -0.07, -0.15, -0.1, -0.12, -0.13, -0.1, -0.08, -0.04, -0.04, -0.01, -0.0, 0.04, -0.04, -0.06, -0.02, -0.03, 0.05, 0.0, 0.03, 0.05, 0.03, 0.04, 0.02, -0.01, -0.01, 0.02, -0.0, -0.07, -0.08, -0.08, -0.1, -0.09, -0.12, -0.03, -0.02, -0.03, -0.01, -0.0, -0.08, 0.01, -0.01, 0.03, 0.03, 0.06, 0.09, 0.09, 0.02, 0.06, 0.06, 0.07, 0.03, 0.05, 0.04, 0.03, -0.0, 0.07, 0.06, -0.01, -0.02, -0.0, 0.03, 0.08, 0.06, 0.09, 0.1, 0.11, 0.03, -0.0, 0.04, -0.01, 0.0, 0.05, 0.05, 0.07, 0.12, 0.1, 0.11, 0.04, 0.03, 0.07, 0.05, 0.07, 0.03, 0.1, 0.05, -0.05, -0.06, 0.01, -0.07, -0.08, -0.07, -0.04, 0.01, -0.04, -0.02, 0.01, 0.02, 0.02, -0.01, -0.01, -0.04, -0.05, 0.01, -0.03, -0.05, -0.04, 0.01, 0.05, 0.04, 0.02, -0.01, -0.07, -0.01, 0.02])]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "could not determine the shape of object type 'DataFrame'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[21], line 5\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[39mprint\u001b[39m(temp_df[\u001b[39m'\u001b[39m\u001b[39mc1\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m.\u001b[39mvalues)\n\u001b[1;32m      4\u001b[0m \u001b[39m#print(temp_df['c1'].astype(int))\u001b[39;00m\n\u001b[0;32m----> 5\u001b[0m ds \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mutils\u001b[39m.\u001b[39mdata\u001b[39m.\u001b[39mTensorDataset(torch\u001b[39m.\u001b[39;49mtensor(temp_df), torch\u001b[39m.\u001b[39mtensor(labels))\n\u001b[1;32m      8\u001b[0m train_loader \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mutils\u001b[39m.\u001b[39mdata\u001b[39m.\u001b[39mDataLoader(ds, batch_size\u001b[39m=\u001b[39m\u001b[39m64\u001b[39m, shuffle\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n\u001b[1;32m      9\u001b[0m \u001b[39mprint\u001b[39m(train_loader)\n",
      "\u001b[0;31mValueError\u001b[0m: could not determine the shape of object type 'DataFrame'"
     ]
    }
   ],
   "source": [
    "torch.tensor(labels)\n",
    "print(temp_df['c1'].values)\n",
    "\n",
    "#print(temp_df['c1'].astype(int))\n",
    "ds = torch.utils.data.TensorDataset(tf.convert_to_tensor(temp_df.values), torch.tensor(labels))\n",
    "\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(ds, batch_size=64, shuffle=False)\n",
    "print(train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(temp_df['c1'].type())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# classes for classification tasks (what sleep stage the mouse is in)\n",
    "# based on labels from annotated data, W is wake, N is Non-REM, R is REM, and A is artifact (unique to our model)\n",
    "\n",
    "classes = {0: \"W\", 1: \"N\", 2: \"R\", 3: \"A\"}"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Creating class for Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" the left hand side of the CNN\"\"\"\n",
    "def CNN_eeg_layer1(fs): \n",
    "    return nn.Sequential(\n",
    "            nn.Conv1d(1, 64, kernel_size=fs//2, stride=2, padding=2),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.MaxPool1d(kernel_size=8, stride=8),\n",
    "            \n",
    "            nn.Conv1d(64, 64, kernel_size=8, padding=2),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv1d(64, 64, kernel_size=8, padding=2),\n",
    "            nn.ReLU(), \n",
    "            nn.Conv1d(64, 64, kernel_size=8, padding=2),\n",
    "            nn.ReLU())\n",
    "\n",
    "\n",
    "class CNN(nn.Module):\n",
    "  \n",
    "    def __init__(self, n_cnn_dense=256, fs=10, num_classes=4):\n",
    "      \n",
    "        super(CNN, self).__init__()\n",
    "        \n",
    "        \"\"\" left and right hand sides of CNNs \"\"\"\n",
    "        self.layer1_eeg = CNN_eeg_layer1(fs)        \n",
    "\n",
    "         # maybe another network at some point for emg?\n",
    "        \n",
    "        # the fully connected layer concatenating the two outputs\n",
    "        self.fc1 = nn.Sequential(\n",
    "            nn.Linear(64, n_cnn_dense),\n",
    "            nn.ReLU(),            \n",
    "            nn.MaxPool1d(kernel_size=4, stride=4))\n",
    "        \n",
    "        self.fc2 = nn.Sequential(\n",
    "            nn.Linear(49, num_classes),\n",
    "            nn.LogSoftmax(dim=1))\n",
    "        \n",
    "                \n",
    "        \n",
    "    def forward(self, channels):\n",
    "      \n",
    "        # at some point, we'll have a second channel for emg\n",
    "        \n",
    "        ch1 = channels # extract eeg channel (Channel 1) from data frame\n",
    "        # ch2 = # extract emg channel (Channel 2) from data frame\n",
    "        \n",
    "        out1_eeg = self.layer1_eeg(ch1)\n",
    "        print(out1_eeg.shape)\n",
    "        out2_eeg = self.layer2_eeg(ch1)\n",
    "        print(out2_eeg.shape)\n",
    "               \n",
    "        # \n",
    "        out = torch.cat((out1_eeg, out2_eeg), dim=1)\n",
    "        out = torch.flatten(out, start_dim=1)\n",
    "        print(out.shape)\n",
    "        out = self.fc1(out)\n",
    "        print(out.shape)\n",
    "        out = torch.flatten(out, start_dim=1)\n",
    "        out = self.fc2(out)\n",
    "\n",
    "        return out"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Training the Model**\n",
    "\n",
    "We can play around with the parameters a bit. I've included the function for counting the number of parameters from the 06-convnet.ipynb from the CSE144 example repo.\n",
    "\n",
    "For our optimization, I used Adam because it converges faster and I don't think our data is well-formatted enough yet to get decent results with SGD."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to count number of parameters\n",
    "def get_n_params(model):\n",
    "    np=0\n",
    "    for p in list(model.parameters()):\n",
    "        np += p.nelement()\n",
    "    return np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make our model\n",
    "model = CNN()\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "# define optimization function and print number of params\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.005)\n",
    "print('Number of parameters: {}'.format(get_n_params(model)))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In one example I saw, they used [model.state_dict()](https://pytorch.org/tutorials/recipes/recipes/what_is_state_dict.html) to record the best learnable parameters (i.e. weights and biases) of a model. They use it for storing the best possible model found during training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, optimizer, scheduler, num_epochs):\n",
    "    \n",
    "    # deep copy and save the best model weights found\n",
    "    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "    # initialize best accuracy found to 0\n",
    "    best_acc = 0.0\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        print('Epoch {}/{}'.format(epoch + 1, num_epochs))\n",
    "        model.train()\n",
    "                \n",
    "        running_loss = 0.0\n",
    "        running_corrects = 0\n",
    "\n",
    "        for inputs, labels in train_loader.dataset:\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # only compute gradients during training, not\n",
    "            # necessary in validations\n",
    "            outputs = model(inputs)\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            loss = torch.nn.functional.nll_loss(outputs, labels)\n",
    "\n",
    "            running_loss += loss.item() * inputs.size(0)\n",
    "            running_corrects += torch.sum(preds == labels.data)\n",
    "\n",
    "            epoch_loss = running_loss / len(train_loader.dataset)\n",
    "            epoch_acc = running_corrects.double() / len(train_loader.dataset)\n",
    "\n",
    "            print('Train Loss: {:.4f} Acc: {:.4f}'.format(epoch_loss, epoch_acc))\n",
    "\n",
    "            if epoch_acc > best_acc:\n",
    "                best_acc = epoch_acc\n",
    "                best_model_wts = copy.deepcopy(model.state_dict())\n",
    "\n",
    "        print()\n",
    "    print('Best Acc: {:4f}'.format(best_acc))\n",
    "\n",
    "    # load best model weights\n",
    "    model.load_state_dict(best_model_wts)\n",
    "    return model"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ignore this, we'll add it back when we get validation data\n",
    "\"\"\"\n",
    "def train_model(model, criteria, optimizer, scheduler, num_epochs):\n",
    "    \n",
    "    # deep copy and save the best model weights found\n",
    "    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "    # initialize best accuracy found to 0\n",
    "    best_acc = 0.0\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        print('Epoch {}/{}'.format(epoch + 1, num_epochs))\n",
    "        for phase in ['train', 'valid']:\n",
    "            if phase == 'train':\n",
    "                scheduler.step()\n",
    "                model.train()  \n",
    "            else:\n",
    "                model.eval()   \n",
    "                \n",
    "            running_loss = 0.0\n",
    "            running_corrects = 0\n",
    "\n",
    "            for inputs, labels in dataloaders[phase]:\n",
    "                inputs = inputs.to(device)\n",
    "                labels = labels.to(device)\n",
    "\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                # only compute gradients during training, not\n",
    "                # necessary in validations\n",
    "                with torch.set_grad_enabled(phase == 'train'):\n",
    "                    outputs = model(inputs)\n",
    "                    _, preds = torch.max(outputs, 1)\n",
    "                    loss = criteria(outputs, labels)\n",
    "\n",
    "                    if phase == 'train':\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "\n",
    "                running_loss += loss.item() * inputs.size(0)\n",
    "                running_corrects += torch.sum(preds == labels.data)\n",
    "\n",
    "            epoch_loss = running_loss / dataset_sizes[phase]\n",
    "            epoch_acc = running_corrects.double() / dataset_sizes[phase]\n",
    "\n",
    "            print('{} Loss: {:.4f} Acc: {:.4f}'.format(\n",
    "                phase, epoch_loss, epoch_acc))\n",
    "\n",
    "            if phase == 'valid' and epoch_acc > best_acc:\n",
    "                best_acc = epoch_acc\n",
    "                best_model_wts = copy.deepcopy(model.state_dict())\n",
    "\n",
    "        print()\n",
    "    print('Best val Acc: {:4f}'.format(best_acc))\n",
    "\n",
    "    # load best model weights\n",
    "    model.load_state_dict(best_model_wts)\n",
    "    return model\n",
    "    \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "sched = optim.lr_scheduler.StepLR(optimizer, step_size=4, gamma=0.1)\n",
    "train_model(model, optimizer,sched, 10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
