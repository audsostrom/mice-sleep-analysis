{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hrVzIHilME_d"
      },
      "source": [
        "**Draft Model for Mice Steep Stage Analysis**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "v448-jrIME_i"
      },
      "outputs": [],
      "source": [
        "import random\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os\n",
        "import re\n",
        "import copy\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import torch\n",
        "from torch import optim, nn\n",
        "from torchvision import transforms, datasets, models\n",
        "\n",
        "from collections import OrderedDict\n",
        "\n",
        "import torch.utils.data as utils\n",
        "\n",
        "from sklearn.preprocessing import LabelBinarizer\n",
        "\n",
        "import tkinter as tk #tk for file dialog (requires Jinja2!!!)\n",
        "from tkinter import filedialog #tkinter for file dialog\n",
        "\n",
        "import re #regex for parsing\n",
        "from os.path import exists\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 393
        },
        "id": "2D54K3Q9ME_l",
        "outputId": "38cea99b-785e-418b-cbf1-f834d0e45127"
      },
      "outputs": [],
      "source": [
        "from inputMassager import *\n",
        "inputHandler = inputMassager()\n",
        "\n",
        "filepath = inputHandler.askForInput(\"Blah!\")\n",
        "\n",
        "#Period Size Variable : effects CNN architecture\n",
        "periodSize = 200\n",
        "\n",
        "#makePeriodFromTxt(self, filepath, periodSize, maxPeriods=None):\n",
        "periods = makePeriodFromTxt(filepath, periodSize, 5000)\n",
        "\n",
        "\n",
        "# target = regan and audreys code ---> This is what will go into the data loader\n",
        "filepath2 = inputHandler.askForInput(\"Blah!\")\n",
        "timestamps = find_time_labels(filepath2)\n",
        "labels, _, _ = label_dataframe_new(periods, timestamps)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sSl7-UG0wJwI"
      },
      "source": [
        "Make a tensor out of eeg data (c1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "zyiayC-svcUb"
      },
      "outputs": [],
      "source": [
        "def getChannelTensors():\n",
        "    #The tensor has to be 3 dimesional with the second dimesion equal to one in order to pass it through a 1d convolutional layer\n",
        "    c1_tensor = torch.zeros((len(periods.c1.values), 1, periodSize)) \n",
        "    c2_tensor = torch.zeros((len(periods.c2.values), 1, periodSize)) \n",
        "    for i in range(len(periods.c1.values)):\n",
        "        c1_tensor[i, 0] = torch.tensor(periods.c1.values[i])\n",
        "        c2_tensor[i, 0] = torch.tensor(periods.c1.values[i])\n",
        "    \n",
        "    return c1_tensor, c2_tensor\n",
        "\n",
        "eeg_samples, emg_samples = getChannelTensors()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oWNKVo4pwAt2"
      },
      "source": [
        "Make the train and validation data loaders  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "HfCwPJdEME_m"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([4, 2, 2,  ..., 2, 2, 2])\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/var/folders/dg/6gzrkj09311g91kn90n1qdcc0000gn/T/ipykernel_45480/1334747039.py:2: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  print(torch.tensor(labels))\n",
            "/var/folders/dg/6gzrkj09311g91kn90n1qdcc0000gn/T/ipykernel_45480/1334747039.py:4: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  ds = torch.utils.data.TensorDataset(eeg_samples, emg_samples, torch.tensor(labels))\n"
          ]
        }
      ],
      "source": [
        "#print(eeg_samples)\n",
        "print(torch.tensor(labels))\n",
        "\n",
        "ds = torch.utils.data.TensorDataset(eeg_samples, emg_samples, torch.tensor(labels))\n",
        "train_dataset, val_dataset = torch.utils.data.random_split(ds, [int(len(ds) *.80), int(len(ds) *.2)])\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=100, shuffle=True)\n",
        "val_loader = torch.utils.data.DataLoader(val_dataset, batch_size=100, shuffle=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "XTMoRVDAv-Kf"
      },
      "outputs": [],
      "source": [
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ARqeTEylME_o"
      },
      "source": [
        "**Creating class for Model**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "O944bgcTwew9"
      },
      "outputs": [],
      "source": [
        "import torch.nn.functional as F\n",
        "from torch import nn, optim\n",
        "\n",
        "\n",
        "class Model_3(nn.Module):\n",
        "    def __init__(self, period_size, input_channels=1):\n",
        "        super(Model_3, self).__init__()\n",
        "        self.input_channels = input_channels\n",
        "\n",
        "        self.eeg_conv1 = nn.Conv1d(in_channels=1, out_channels=period_size, kernel_size=period_size//2)\n",
        "        self.eeg_conv2 = nn.Conv1d(in_channels=period_size, out_channels=period_size//4, kernel_size=8)\n",
        "        self.eeg_conv3 = nn.Conv1d(in_channels=period_size // 4, out_channels=256, kernel_size=2)\n",
        "\n",
        "        self.emg_conv1 = nn.Conv1d(in_channels=1, out_channels=period_size, kernel_size=period_size//2)\n",
        "        self.emg_conv2 = nn.Conv1d(in_channels=period_size, out_channels=period_size//4, kernel_size=8)\n",
        "        self.emg_conv3 = nn.Conv1d(in_channels=period_size // 4, out_channels=256, kernel_size=2)\n",
        "\n",
        "\n",
        "\n",
        "        # out_channels and kernal size are random\n",
        "        self.fc1 = nn.Linear(2560*2, 20) # 10 is random\n",
        "        self.fc2 = nn.Linear(10, 5)\n",
        "\n",
        "\n",
        "    def forward(self, c1, c2):\n",
        "        #print(x.size())\n",
        "        c1 = self.eeg_conv1(c1)\n",
        "        c1 = F.relu(c1)\n",
        "        # print(x.size())\n",
        "        c1 = F.max_pool1d(c1, kernel_size=2)\n",
        "        c1 = self.eeg_conv2(c1)\n",
        "        c1 = F.max_pool1d(c1, kernel_size=2)\n",
        "        # print(x.size())\n",
        "        c1 = self.eeg_conv3(c1)\n",
        "        c1 = F.max_pool1d(c1, kernel_size=2)\n",
        "        #print(x.size())\n",
        "\n",
        "        c2 = self.eeg_conv1(c2)\n",
        "        c2 = F.relu(c2)\n",
        "        # print(x.size())\n",
        "        c2 = F.max_pool1d(c2, kernel_size=2)\n",
        "        c2 = self.eeg_conv2(c2)\n",
        "        c2 = F.max_pool1d(c2, kernel_size=2)\n",
        "        # print(x.size())\n",
        "        c2 = self.eeg_conv3(c2)\n",
        "        c2 = F.max_pool1d(c2, kernel_size=2)\n",
        "\n",
        "\n",
        "        c1c2 = torch.cat((c1, c2), dim=1)\n",
        "\n",
        "        c1c2 = c1c2.flatten(1)\n",
        "        #print(x.size())\n",
        "        c1c2 = self.fc1(c1c2)\n",
        "        c1c2 = F.max_pool1d(c1c2, kernel_size=2)\n",
        "        # print(x.size())\n",
        "        c1c2 = self.fc2(c1c2)\n",
        "        c1c2 = F.log_softmax(c1c2, dim=1)\n",
        "        return c1c2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "_ctcO4-KME_o"
      },
      "outputs": [],
      "source": [
        "def train_model(epochs, model):\n",
        "    model.train() # set model to training mode\n",
        "    loss_fun = nn.CrossEntropyLoss() #define a loss function object\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "\n",
        "      for batch_idx, (channel1, channel2, target) in enumerate(train_loader):\n",
        "          #print(c)\n",
        "          # print(target)\n",
        "          channel1, channel2, target = channel1.to(device), channel2.to(device), target.to(device)\n",
        "          \n",
        "          optimizer.zero_grad()\n",
        "          output = model(channel1, channel2) # guess we have to pass all channels instead of data?\n",
        "          loss = loss_fun(output,target)\n",
        "          loss.backward()\n",
        "          optimizer.step()\n",
        "          if batch_idx % 100 == 0:\n",
        "              print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
        "                  epoch, batch_idx * len(channel1), len(train_loader.dataset),\n",
        "                  100. * batch_idx / len(train_loader), loss.item()))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "zWd70Kxjwyir"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Epoch: 0 [0/4000 (0%)]\tLoss: 1.540055\n",
            "Train Epoch: 1 [0/4000 (0%)]\tLoss: 0.685793\n",
            "Train Epoch: 2 [0/4000 (0%)]\tLoss: 0.263564\n"
          ]
        }
      ],
      "source": [
        "model_step_3 = Model_3(periodSize)\n",
        "model_step_3.to(device)\n",
        "  \n",
        "optimizer = torch.optim.SGD(model_step_3.parameters(), lr=.01, momentum=0.9)\n",
        "train_model(3, model_step_3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "xX-YQFBoxmAa"
      },
      "outputs": [],
      "source": [
        "def evaluate_model(model, dataloader, is_test=False):\n",
        "  #Evaluation\n",
        "\n",
        "  # Set model to evaluation mode\n",
        "  model.eval()\n",
        "\n",
        "  with torch.no_grad():\n",
        "    correct = 0\n",
        "    loss = 0\n",
        "\n",
        "    criterion = torch.nn.CrossEntropyLoss(reduction='none')\n",
        "\n",
        "    for channel1, channel2, target in dataloader:\n",
        "        channel1, channel2, target = channel1.to(device), channel2.to(device), target.to(device)\n",
        "        outputs = model(channel1, channel2)\n",
        "        \n",
        "        loss += torch.sum(criterion(outputs, target)).item()\n",
        "        \n",
        "        pred = outputs.data.max(1, keepdim=True)[1] # get the index of the max log-probability                                                                 \n",
        "        correct += pred.eq(target.data.view_as(pred)).cpu().sum().item()\n",
        "\n",
        "    loss /= len(dataloader.dataset)\n",
        "    accuracy = 100. * correct / len(dataloader.dataset)\n",
        "    print('\\n{} set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
        "        \"Test\" if is_test else \"Validation\",\n",
        "        loss, correct, len(dataloader.dataset),\n",
        "        accuracy))\n",
        "  # Set model back to training mode\n",
        "  model.train()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "WXAO7Fpkxmqa"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Test set: Average loss: 0.1972, Accuracy: 946/1000 (95%)\n",
            "\n"
          ]
        }
      ],
      "source": [
        "evaluate_model(model_step_3, val_loader, is_test=True)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.2"
    },
    "orig_nbformat": 4
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
