{
  "cells": [
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "hrVzIHilME_d"
      },
      "source": [
        "**Draft Model for Mice Steep Stage Analysis**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "v448-jrIME_i"
      },
      "outputs": [],
      "source": [
        "import random\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os\n",
        "import re\n",
        "import copy\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import torch\n",
        "from torch import optim, nn\n",
        "from torchvision import transforms, datasets, models\n",
        "\n",
        "from collections import OrderedDict\n",
        "\n",
        "import torch.utils.data as utils\n",
        "\n",
        "import tkinter as tk #tk for file dialog (requires Jinja2!!!)\n",
        "from tkinter import filedialog #tkinter for file dialog\n",
        "\n",
        "import re #regex for parsing\n",
        "from os.path import exists\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 393
        },
        "id": "2D54K3Q9ME_l",
        "outputId": "38cea99b-785e-418b-cbf1-f834d0e45127"
      },
      "outputs": [
        {
          "ename": "TclError",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTclError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-6-47ed554e67a2>\u001b[0m in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0minputHandler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minputMassager\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mfilepath\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minputHandler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maskForInput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Blah!\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m#Period Size Variable : effects CNN architecture\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/inputMassager.py\u001b[0m in \u001b[0;36maskForInput\u001b[0;34m(self, title_msg)\u001b[0m\n\u001b[1;32m     25\u001b[0m         \u001b[0;31m# Returns filepath\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0maskForInput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtitle_msg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"Select Data File\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m                 \u001b[0mroot\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTk\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m#init tkinter root\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m                 \u001b[0mroot\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwithdraw\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#Hide root window\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/tkinter/__init__.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, screenName, baseName, className, useTk, sync, use)\u001b[0m\n\u001b[1;32m   2300\u001b[0m                 \u001b[0mbaseName\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbaseName\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mext\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2301\u001b[0m         \u001b[0minteractive\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2302\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtk\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_tkinter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscreenName\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbaseName\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclassName\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minteractive\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwantobjects\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0museTk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msync\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2303\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0museTk\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2304\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_loadtk\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTclError\u001b[0m: no display name and no $DISPLAY environment variable"
          ]
        }
      ],
      "source": [
        "from inputMassager import *\n",
        "inputHandler = inputMassager()\n",
        "\n",
        "filepath = (\"CHD801FR_20221123_normal.txt\")\n",
        "\n",
        "#Period Size Variable : effects CNN architecture\n",
        "periodSize = 200\n",
        "\n",
        "#makePeriodFromTxt(self, filepath, periodSize, maxPeriods=None):\n",
        "periods = inputHandler.makePeriodFromTxt(filepath, periodSize, 2000)\n",
        "\n",
        "\n",
        "# target = regan and audreys code ---> This is what will go into the data loader\n",
        "filepath2 = (\"CHDCtrl1_CHD801FR_normal_annotatedl.txt\")\n",
        "\n",
        "timestamps = find_time_labels(df, filepath2)#2d list of stop times and corresponding labels from annotated data\n",
        "labels = label_dataframe(periods, timestamps)#list of the corresponding label for each period based on timestamps\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "sSl7-UG0wJwI"
      },
      "source": [
        "Makes 3d tensor out of period data for either the eeg(c1) or emg(c2) column\n",
        "\n",
        "the tensor is size [number of samples, 1, period_size], it needs to be this shape becasue the 2nd dimesion of an input tensor is interpreted as the number of input channels by convoluntional layers\n",
        "\n",
        "when you concatanate the eeg samples and emg samples, it becomes a [number of samples, 2, period_size] tensor and emg becomes another channel"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zyiayC-svcUb"
      },
      "outputs": [],
      "source": [
        "def getColTensor(col):\n",
        "    #The tensor has to be 3 dimesional with the second dimesion equal to one in order to pass it through a 1d convolutional layer\n",
        "    col_tensor = torch.zeros((len(periods[col].values), 1, periodSize))\n",
        "\n",
        "    for i in range(len(periods[col].values)):\n",
        "        col_tensor[i, 0] = torch.tensor(periods[col].values[i])\n",
        "    \n",
        "    return col_tensor\n",
        "\n",
        "eeg_samples = getColTensor()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "eeg_samples = getColTensor(\"c1\")\n",
        "emg_samples =  getColTensor(\"c2\")\n",
        "\n",
        "both_samples = torch.cat((eeg_samples, emg_samples), 1)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "This is supposed to get only the first 2000 appearances of rem, non-rem and wake data (for a total of 6000) so that we don't just have a ton of one and we can get a little better idea of how the model might actually do but it'll mess up the order near the end becuase once it's hit for instance 2000 wake states, it'll stop getting those so we'll lose the timing context, i'm ot sure if it actully useful but if you do use, i think you probably wan to set shuffle to true"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def equalRepresentation():\n",
        "    \n",
        "    count1, count2, count3 = 0, 0, 0\n",
        "    f_labels = []\n",
        "    f_periods = [[],[]]\n",
        "\n",
        "    for i in range(len(labels)):\n",
        "        if labels[i] == 1 and count1 < 2000:\n",
        "            f_labels.append(labels[i])\n",
        "            f_periods[0].append(periods[\"c1\"][i])\n",
        "            f_periods[1].append(periods[\"c2\"][i])\n",
        "            count1+= 1\n",
        "\n",
        "        if labels[i] == 2 and count2 < 2000:\n",
        "            f_labels.append(labels[i])\n",
        "            f_periods[0].append(periods[\"c1\"][i])\n",
        "            f_periods[1].append(periods[\"c2\"][i])\n",
        "            count2+= 1\n",
        "\n",
        "        if labels[i] == 3 and count3 < 2000:\n",
        "            f_labels.append(labels[i])\n",
        "            f_periods[0].append(periods[\"c1\"][i])\n",
        "            f_periods[1].append(periods[\"c2\"][i])\n",
        "            count3+= 1\n",
        "\n",
        "    return f_labels, f_periods"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "f_labels, f_periods = equalRepresentation()"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "getColTensor for equal representation samples"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def equal_getColTensor(col = 0):\n",
        "    col_tensor = torch.zeros((len(f_periods[0]), 1, 200))\n",
        "\n",
        "    for i in range(len(f_periods[0])):\n",
        "        col_tensor[i, 0] = torch.tensor(f_periods[col][i])\n",
        "    \n",
        "    return col_tensor\n",
        "\n",
        "equal_eeg_samples = equal_getColTensor(0)\n",
        "equal_emg_samples = equal_getColTensor(1)\n",
        "\n",
        "equal_both_samples = torch.cat((eeg_samples, emg_samples), 1)\n",
        "equal_labels = torch.tensor(f_labels)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "oWNKVo4pwAt2"
      },
      "source": [
        "Make the train and validation data loaders  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HfCwPJdEME_m"
      },
      "outputs": [],
      "source": [
        "ds = torch.utils.data.TensorDataset(both_samples, torch.tensor(labels))\n",
        "\n",
        "train_size = int(len(ds) *.80)\n",
        "val_size = len(ds) - int(len(ds) *.80)\n",
        "\n",
        "train_dataset, val_dataset = torch.utils.data.random_split(ds, [train_size, val_size])\n",
        "\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=100, shuffle = False)\n",
        "val_loader = torch.utils.data.DataLoader(val_dataset, batch_size=100, shuffle=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XTMoRVDAv-Kf"
      },
      "outputs": [],
      "source": [
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "ARqeTEylME_o"
      },
      "source": [
        "**Creating class for Model**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O944bgcTwew9"
      },
      "outputs": [],
      "source": [
        "import torch.nn.functional as F\n",
        "from torch import nn, optim\n",
        "\n",
        "\n",
        "class CNN(nn.Module):\n",
        "    #takes just one input for the number of input channels, right now if you're using both eeg and emg it's 2 and if youre just using one of them, its 1    \n",
        "    def __init__(self, in_vars):\n",
        "        super(CNN, self).__init__()\n",
        "\n",
        "        #out_channels and kernal size are random        \n",
        "        self.conv1 = nn.Conv1d(in_channels=in_vars, out_channels= 100, kernel_size=2)\n",
        "\n",
        "        #the second number should be the number of classifications, it's 5 now becuase the clasifcications range from 1-4 but it should be 4 so artificat should eventually be 0  \n",
        "        self.fc1 = nn.Linear(9900, 5)\n",
        "\n",
        "\n",
        "    def forward(self, x, verbose=False):\n",
        "\n",
        "        x = self.conv1(x)\n",
        "        x = F.relu(x)\n",
        "        #print(x.size())\n",
        "\n",
        "        x = F.max_pool1d(x, kernel_size=2)#kernal size is random\n",
        "        #print(x.size())\n",
        "        \n",
        "        x = x.flatten(1)\n",
        "        #print(x.size())\n",
        "\n",
        "        x = self.fc1(x)\n",
        "        x = F.log_softmax(x, dim=1)#softmax is random\n",
        "\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "_ctcO4-KME_o"
      },
      "outputs": [],
      "source": [
        "def train_model(epochs, model):\n",
        "    model.train()#set model to training mode\n",
        "    loss_fun = nn.CrossEntropyLoss()#define a loss function object\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "\n",
        "      for batch_idx, (data, target) in enumerate(train_loader):\n",
        "          data, target = data.to(device), target.to(device)\n",
        "          \n",
        "          optimizer.zero_grad()\n",
        "          output = model(data)\n",
        "          loss = loss_fun(output,target)\n",
        "          loss.backward()\n",
        "          optimizer.step()\n",
        "          if batch_idx % 100 == 0:\n",
        "              print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
        "                  epoch, batch_idx * len(data), len(train_loader.dataset),\n",
        "                  100. * batch_idx / len(train_loader), loss.item()))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zWd70Kxjwyir"
      },
      "outputs": [],
      "source": [
        "basic_cnn = CNN(2)\n",
        "basic_cnn.to(device)\n",
        "  \n",
        "optimizer = torch.optim.SGD(basic_cnn.parameters(), lr=.01)\n",
        "train_model(10, basic_cnn)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xX-YQFBoxmAa"
      },
      "outputs": [],
      "source": [
        "def evaluate_model(model, dataloader, is_test=False):\n",
        "  #Evaluation\n",
        "\n",
        "  # Set model to evaluation mode\n",
        "  model.eval()\n",
        "\n",
        "  with torch.no_grad():\n",
        "    correct = 0\n",
        "    loss = 0\n",
        "\n",
        "    criterion = torch.nn.CrossEntropyLoss(reduction='none')\n",
        "\n",
        "    for data, target in dataloader:\n",
        "        data, target = data.to(device), target.to(device)\n",
        "        outputs = model(data)\n",
        "        \n",
        "        loss += torch.sum(criterion(outputs, target)).item()\n",
        "        \n",
        "        pred = outputs.data.max(1, keepdim=True)[1] # get the index of the max log-probability                                                                 \n",
        "        correct += pred.eq(target.data.view_as(pred)).cpu().sum().item()\n",
        "\n",
        "    loss /= len(dataloader.dataset)\n",
        "    accuracy = 100. * correct / len(dataloader.dataset)\n",
        "    print('\\n{} set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
        "        \"Test\" if is_test else \"Validation\",\n",
        "        loss, correct, len(dataloader.dataset),\n",
        "        accuracy))\n",
        "  # Set model back to training mode\n",
        "  model.train()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WXAO7Fpkxmqa"
      },
      "outputs": [],
      "source": [
        "evaluate_model(basic_cnn, val_loader, is_test=True)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.2"
    },
    "orig_nbformat": 4
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
