{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hrVzIHilME_d"
      },
      "source": [
        "**Draft Model for Mice Steep Stage Analysis**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v448-jrIME_i"
      },
      "outputs": [],
      "source": [
        "import random\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os\n",
        "import re\n",
        "import copy\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import torch\n",
        "from torch import optim, nn\n",
        "from torchvision import transforms, datasets, models\n",
        "\n",
        "from collections import OrderedDict\n",
        "\n",
        "import torch.utils.data as utils\n",
        "\n",
        "from sklearn.preprocessing import LabelBinarizer\n",
        "\n",
        "import tkinter as tk #tk for file dialog (requires Jinja2!!!)\n",
        "from tkinter import filedialog #tkinter for file dialog\n",
        "\n",
        "import re #regex for parsing\n",
        "from os.path import exists\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 393
        },
        "id": "2D54K3Q9ME_l",
        "outputId": "38cea99b-785e-418b-cbf1-f834d0e45127"
      },
      "outputs": [],
      "source": [
        "from inputMassager import *\n",
        "inputHandler = inputMassager()\n",
        "\n",
        "filepath = inputHandler.askForInput(\"Blah!\")\n",
        "\n",
        "#Period Size Variable : effects CNN architecture\n",
        "periodSize = 200\n",
        "\n",
        "#makePeriodFromTxt(self, filepath, periodSize, maxPeriods=None):\n",
        "periods = makePeriodFromTxt(filepath, periodSize, 5000)\n",
        "\n",
        "\n",
        "# target = regan and audreys code ---> This is what will go into the data loader\n",
        "filepath2 = inputHandler.askForInput(\"Blah!\")\n",
        "timestamps = find_time_labels(filepath2)\n",
        "labels, _, _ = label_dataframe_new(periods, timestamps)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sSl7-UG0wJwI"
      },
      "source": [
        "Make a tensor out of eeg data (c1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "zyiayC-svcUb"
      },
      "outputs": [],
      "source": [
        "def getChannelTensors():\n",
        "    #The tensor has to be 3 dimesional with the second dimesion equal to one in order to pass it through a 1d convolutional layer\n",
        "    c1_tensor = torch.zeros((len(periods.c1.values), 1, periodSize)) \n",
        "    c2_tensor = torch.zeros((len(periods.c2.values), 1, periodSize)) \n",
        "    for i in range(len(periods.c1.values)):\n",
        "        c1_tensor[i, 0] = torch.tensor(periods.c1.values[i])\n",
        "        c2_tensor[i, 0] = torch.tensor(periods.c1.values[i])\n",
        "    \n",
        "    return c1_tensor, c2_tensor\n",
        "\n",
        "eeg_samples, emg_samples = getChannelTensors()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oWNKVo4pwAt2"
      },
      "source": [
        "Make the train and validation data loaders  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "HfCwPJdEME_m"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([4, 2, 2,  ..., 2, 2, 2])\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/var/folders/dg/6gzrkj09311g91kn90n1qdcc0000gn/T/ipykernel_73804/29316696.py:2: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  print(torch.tensor(labels))\n",
            "/var/folders/dg/6gzrkj09311g91kn90n1qdcc0000gn/T/ipykernel_73804/29316696.py:6: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  ds = torch.utils.data.TensorDataset(eeg_samples, torch.tensor(labels))\n"
          ]
        }
      ],
      "source": [
        "#print(eeg_samples)\n",
        "print(torch.tensor(labels))\n",
        "\n",
        "ds = torch.utils.data.TensorDataset(eeg_samples, torch.tensor(labels))\n",
        "train_dataset, val_dataset = torch.utils.data.random_split(ds, [int(len(ds) *.80), int(len(ds) *.2)])\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=100, shuffle=True)\n",
        "val_loader = torch.utils.data.DataLoader(val_dataset, batch_size=100, shuffle=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "XTMoRVDAv-Kf"
      },
      "outputs": [],
      "source": [
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ARqeTEylME_o"
      },
      "source": [
        "**Creating class for Model**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "id": "O944bgcTwew9"
      },
      "outputs": [],
      "source": [
        "class SimpleRNN(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, output_size):\n",
        "        # This just calls the base class constructor\n",
        "        super().__init__()\n",
        "        # Neural network layers assigned as attributes of a Module subclass\n",
        "        # have their parameters registered for training automatically.\n",
        "\n",
        "        # batch_first=True\n",
        "        self.rnn = torch.nn.RNN(input_size, hidden_size, nonlinearity='relu')\n",
        "        self.linear = torch.nn.Linear(hidden_size, output_size)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # The RNN also returns its hidden state but we don't use it.\n",
        "        # While the RNN can also take a hidden state as input, the RNN\n",
        "        # gets passed a hidden state initialized with zeros by default.\n",
        "        print('size of x', x.size())\n",
        "        h = self.rnn(x)[0]\n",
        "        print('shape of h', h.shape())\n",
        "        x = self.linear(h)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {},
      "outputs": [],
      "source": [
        "def train(model, train_data_gen, criterion, optimizer, device):\n",
        "    # Set the model to training mode. This will turn on layers that would\n",
        "    # otherwise behave differently during evaluation, such as dropout.\n",
        "    model.train()\n",
        "\n",
        "    # Store the number of sequences that were classified correctly\n",
        "    num_correct = 0\n",
        "\n",
        "    # Iterate over every batch of sequences. Note that the length of a data generator\n",
        "    # is defined as the number of batches required to produce a total of roughly 1000\n",
        "    # sequences given a batch size.\n",
        "    for batch_idx, (data, target) in enumerate(train_data_gen):\n",
        "        data, target = data.to(device), target.to(device)\n",
        "\n",
        "        # Perform the forward pass of the model\n",
        "        output = model(data)  # Step ①\n",
        "\n",
        "        output = output[:, -1, :]\n",
        "\n",
        "        # Compute the value of the loss for this batch. For loss functions like CrossEntropyLoss,\n",
        "        # the second argument is actually expected to be a tensor of class indices rather than\n",
        "        # one-hot encoded class labels. One approach is to take advantage of the one-hot encoding\n",
        "        # of the target and call argmax along its second dimension to create a tensor of shape\n",
        "        # (batch_size) containing the index of the class label that was hot for each sequence.\n",
        "        target = target.argmax(dim=1)\n",
        "\n",
        "        loss = criterion(output, target)  # Step ②\n",
        "\n",
        "        # Clear the gradient buffers of the optimized parameters.\n",
        "        # Otherwise, gradients from the previous batch would be accumulated.\n",
        "        optimizer.zero_grad()  # Step ③\n",
        "\n",
        "        loss.backward()  # Step ④\n",
        "\n",
        "        optimizer.step()  # Step ⑤\n",
        "\n",
        "        y_pred = output.argmax(dim=1)\n",
        "        num_correct += (y_pred == target).sum().item()\n",
        "\n",
        "    return num_correct, loss.item()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {},
      "outputs": [],
      "source": [
        "def test(model, test_data_gen, criterion, device):\n",
        "    # Set the model to evaluation mode. This will turn off layers that would\n",
        "    # otherwise behave differently during training, such as dropout.\n",
        "    model.eval()\n",
        "\n",
        "    # Store the number of sequences that were classified correctly\n",
        "    num_correct = 0\n",
        "\n",
        "    # A context manager is used to disable gradient calculations during inference\n",
        "    # to reduce memory usage, as we typically don't need the gradients at this point.\n",
        "    with torch.no_grad():\n",
        "        for batch_idx, (data, target) in enumerate(test_data_gen):\n",
        "\n",
        "            data, target = data.to(device), target.to(device)\n",
        "\n",
        "            output = model(data)\n",
        "\n",
        "            target = target.argmax(dim=1)\n",
        "            loss = criterion(output, target)\n",
        "\n",
        "            y_pred = output.argmax(dim=1)\n",
        "            num_correct += (y_pred == target).sum().item()\n",
        "\n",
        "    return num_correct, loss.item()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {},
      "outputs": [],
      "source": [
        "def train_and_test(model, train_data_gen, test_data_gen, criterion, optimizer, max_epochs, verbose=True):\n",
        "    # Automatically determine the device that PyTorch should use for computation\n",
        "    device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "    # Move model to the device which will be used for train and test\n",
        "    model.to(device)\n",
        "\n",
        "    # Track the value of the loss function and model accuracy across epochs\n",
        "    history_train = {'loss': [], 'acc': []}\n",
        "    history_test = {'loss': [], 'acc': []}\n",
        "\n",
        "    for epoch in range(max_epochs):\n",
        "        # Run the training loop and calculate the accuracy.\n",
        "        # Remember that the length of a data generator is the number of batches,\n",
        "        # so we multiply it by the batch size to recover the total number of sequences.\n",
        "        num_correct, loss = train(model, train_data_gen, criterion, optimizer, device)\n",
        "        accuracy = float(num_correct) / (len(train_data_gen) * train_data_gen.batch_size) * 100\n",
        "        history_train['loss'].append(loss)\n",
        "        history_train['acc'].append(accuracy)\n",
        "\n",
        "        # Do the same for the testing loop\n",
        "        num_correct, loss = test(model, test_data_gen, criterion, device)\n",
        "        accuracy = float(num_correct) / (len(test_data_gen) * test_data_gen.batch_size) * 100\n",
        "        history_test['loss'].append(loss)\n",
        "        history_test['acc'].append(accuracy)\n",
        "\n",
        "        if verbose or epoch + 1 == max_epochs:\n",
        "            print(f'[Epoch {epoch + 1}/{max_epochs}]'\n",
        "                  f\" loss: {history_train['loss'][-1]:.4f}, acc: {history_train['acc'][-1]:2.2f}%\"\n",
        "                  f\" - test_loss: {history_test['loss'][-1]:.4f}, test_acc: {history_test['acc'][-1]:2.2f}%\")\n",
        "\n",
        "    # Generate diagnostic plots for the loss and accuracy\n",
        "    fig, axes = plt.subplots(ncols=2, figsize=(9, 4.5))\n",
        "    for ax, metric in zip(axes, ['loss', 'acc']):\n",
        "        ax.plot(history_train[metric])\n",
        "        ax.plot(history_test[metric])\n",
        "        ax.set_xlabel('epoch', fontsize=12)\n",
        "        ax.set_ylabel(metric, fontsize=12)\n",
        "        ax.legend(['Train', 'Test'], loc='best')\n",
        "    plt.show()\n",
        "\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "size of x torch.Size([100, 1, 200])\n"
          ]
        },
        {
          "ename": "RuntimeError",
          "evalue": "input.size(-1) must be equal to input_size. Expected 40, got 200",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[57], line 15\u001b[0m\n\u001b[1;32m     12\u001b[0m max_epochs  \u001b[39m=\u001b[39m \u001b[39m3\u001b[39m\n\u001b[1;32m     14\u001b[0m \u001b[39m# Train the model\u001b[39;00m\n\u001b[0;32m---> 15\u001b[0m train(model, train_loader, criterion, optimizer, device)\n\u001b[1;32m     16\u001b[0m train(model, val_loader, criterion, optimizer, device)\n",
            "Cell \u001b[0;32mIn[54], line 16\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(model, train_data_gen, criterion, optimizer, device)\u001b[0m\n\u001b[1;32m     13\u001b[0m data, target \u001b[39m=\u001b[39m data\u001b[39m.\u001b[39mto(device), target\u001b[39m.\u001b[39mto(device)\n\u001b[1;32m     15\u001b[0m \u001b[39m# Perform the forward pass of the model\u001b[39;00m\n\u001b[0;32m---> 16\u001b[0m output \u001b[39m=\u001b[39m model(data)  \u001b[39m# Step ①\u001b[39;00m\n\u001b[1;32m     18\u001b[0m output \u001b[39m=\u001b[39m output[:, \u001b[39m-\u001b[39m\u001b[39m1\u001b[39m, :]\n\u001b[1;32m     20\u001b[0m \u001b[39m# Compute the value of the loss for this batch. For loss functions like CrossEntropyLoss,\u001b[39;00m\n\u001b[1;32m     21\u001b[0m \u001b[39m# the second argument is actually expected to be a tensor of class indices rather than\u001b[39;00m\n\u001b[1;32m     22\u001b[0m \u001b[39m# one-hot encoded class labels. One approach is to take advantage of the one-hot encoding\u001b[39;00m\n\u001b[1;32m     23\u001b[0m \u001b[39m# of the target and call argmax along its second dimension to create a tensor of shape\u001b[39;00m\n\u001b[1;32m     24\u001b[0m \u001b[39m# (batch_size) containing the index of the class label that was hot for each sequence.\u001b[39;00m\n",
            "File \u001b[0;32m~/Library/Python/3.8/lib/python/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
            "Cell \u001b[0;32mIn[53], line 17\u001b[0m, in \u001b[0;36mSimpleRNN.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, x):\n\u001b[1;32m     13\u001b[0m     \u001b[39m# The RNN also returns its hidden state but we don't use it.\u001b[39;00m\n\u001b[1;32m     14\u001b[0m     \u001b[39m# While the RNN can also take a hidden state as input, the RNN\u001b[39;00m\n\u001b[1;32m     15\u001b[0m     \u001b[39m# gets passed a hidden state initialized with zeros by default.\u001b[39;00m\n\u001b[1;32m     16\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39msize of x\u001b[39m\u001b[39m'\u001b[39m, x\u001b[39m.\u001b[39msize())\n\u001b[0;32m---> 17\u001b[0m     h \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mrnn(x)\n\u001b[1;32m     18\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39mshape of h\u001b[39m\u001b[39m'\u001b[39m, h\u001b[39m.\u001b[39mshape())\n\u001b[1;32m     19\u001b[0m     x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlinear(h)\n",
            "File \u001b[0;32m~/Library/Python/3.8/lib/python/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
            "File \u001b[0;32m~/Library/Python/3.8/lib/python/site-packages/torch/nn/modules/rnn.py:505\u001b[0m, in \u001b[0;36mRNN.forward\u001b[0;34m(self, input, hx)\u001b[0m\n\u001b[1;32m    502\u001b[0m     hx \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpermute_hidden(hx, sorted_indices)\n\u001b[1;32m    504\u001b[0m \u001b[39massert\u001b[39;00m hx \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m--> 505\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcheck_forward_args(\u001b[39minput\u001b[39;49m, hx, batch_sizes)\n\u001b[1;32m    506\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmode \u001b[39m==\u001b[39m \u001b[39m'\u001b[39m\u001b[39mRNN_TANH\u001b[39m\u001b[39m'\u001b[39m \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmode \u001b[39m==\u001b[39m \u001b[39m'\u001b[39m\u001b[39mRNN_RELU\u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m    507\u001b[0m \u001b[39mif\u001b[39;00m batch_sizes \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
            "File \u001b[0;32m~/Library/Python/3.8/lib/python/site-packages/torch/nn/modules/rnn.py:253\u001b[0m, in \u001b[0;36mRNNBase.check_forward_args\u001b[0;34m(self, input, hidden, batch_sizes)\u001b[0m\n\u001b[1;32m    252\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mcheck_forward_args\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m: Tensor, hidden: Tensor, batch_sizes: Optional[Tensor]):\n\u001b[0;32m--> 253\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcheck_input(\u001b[39minput\u001b[39;49m, batch_sizes)\n\u001b[1;32m    254\u001b[0m     expected_hidden_size \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mget_expected_hidden_size(\u001b[39minput\u001b[39m, batch_sizes)\n\u001b[1;32m    256\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcheck_hidden_size(hidden, expected_hidden_size)\n",
            "File \u001b[0;32m~/Library/Python/3.8/lib/python/site-packages/torch/nn/modules/rnn.py:218\u001b[0m, in \u001b[0;36mRNNBase.check_input\u001b[0;34m(self, input, batch_sizes)\u001b[0m\n\u001b[1;32m    214\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(\n\u001b[1;32m    215\u001b[0m         \u001b[39m'\u001b[39m\u001b[39minput must have \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m dimensions, got \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mformat(\n\u001b[1;32m    216\u001b[0m             expected_input_dim, \u001b[39minput\u001b[39m\u001b[39m.\u001b[39mdim()))\n\u001b[1;32m    217\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39minput_size \u001b[39m!=\u001b[39m \u001b[39minput\u001b[39m\u001b[39m.\u001b[39msize(\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m):\n\u001b[0;32m--> 218\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(\n\u001b[1;32m    219\u001b[0m         \u001b[39m'\u001b[39m\u001b[39minput.size(-1) must be equal to input_size. Expected \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m, got \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mformat(\n\u001b[1;32m    220\u001b[0m             \u001b[39mself\u001b[39m\u001b[39m.\u001b[39minput_size, \u001b[39minput\u001b[39m\u001b[39m.\u001b[39msize(\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m)))\n",
            "\u001b[0;31mRuntimeError\u001b[0m: input.size(-1) must be equal to input_size. Expected 40, got 200"
          ]
        }
      ],
      "source": [
        "# Setup the RNN and training settings\n",
        "\n",
        "# doing len(train_dataset) gives the number of batches\n",
        "\n",
        "#rows, columns = train_dataset.get_shape()\n",
        "input_size  = len(train_loader)\n",
        "hidden_size = 50\n",
        "output_size = 4\n",
        "model       = SimpleRNN(input_size, hidden_size, output_size)\n",
        "criterion   = torch.nn.CrossEntropyLoss()\n",
        "optimizer   = torch.optim.RMSprop(model.parameters(), lr=0.001)\n",
        "max_epochs  = 3\n",
        "\n",
        "# Train the model\n",
        "train(model, train_loader, criterion, optimizer, device)\n",
        "train(model, val_loader, criterion, optimizer, device)\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.2"
    },
    "orig_nbformat": 4
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
